{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46912e-c03d-4cdf-b0aa-c54ae2d71a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a6e1a-b54a-4e56-a36b-bfaeabae78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the folder you want to import from\n",
    "sys.path.append(os.path.abspath('../EasyEdit/'))\n",
    "\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "MULTI = True\n",
    "\n",
    "if not MULTI:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{DEVICE_NUM}\" # '' #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12f28-187b-4af3-94fb-3c491392fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fbc11-c1e1-41ce-8abc-1173e9163d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer\n",
    "import random\n",
    "\n",
    "\n",
    "#device = f\"cuda:{DEVICE_NUM}\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "model_type = 'gpt-j' #'gpt-neo' #\n",
    "models = ['6B'] #['1.3B', '2.7B'] #\n",
    "model_size = models[0]\n",
    "\n",
    "\n",
    "if model_type == 'gpt-j':\n",
    "    model_name = f\"EleutherAI/gpt-j-{model_size}\"\n",
    "elif model_type == 'gpt-neo':\n",
    "    model_name = f\"EleutherAI/gpt-neo-{model_size}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa0f4e-fb5d-4feb-99f3-d37f640fe083",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_type}-{model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39aab1-aade-4e95-a7f2-9e74de55e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2adb7-28de-4653-bcf3-16203e5f5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = 200\n",
    "\n",
    "UPDATE_METHODS = ['pre_edit', f'memoedit-{CONTEXT}', f'MEMIT-{CONTEXT}', \n",
    "                  f'dememorize-{CONTEXT}', f'GRACE-{CONTEXT}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770b2f2-4eb7-4cda-9ee7-8042f53c8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval import tasks, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccce072-d681-4f20-9087-135600072b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the task you want to evaluate on\n",
    "TASKS = [\"hellaswag\", \"lambada\", 'wikitext', 'winogrande', 'piqa']  \n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b01760-b037-468e-8737-5f4b62e2eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbe693-22af-4c42-bc1d-2181be360a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyeditor.models.grace.GRACE import GRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c8360-9476-4289-b3bd-e183e57ff1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "    \n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as pickle_handler:\n",
    "        results = pickle.load(pickle_handler)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25dbcf0-5fb7-4ab2-ac06-6a61810c6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_type= 'email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc23e9d-ea2e-4f6f-9a1a-9a22b7f5f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"lm-eval-harness-res-{model_type}-{model_size}-{pii_type}\"):\n",
    "    os.mkdir(f\"lm-eval-harness-res-{model_type}-{model_size}-{pii_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3159a-122c-4317-bddb-4876ef6f7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec47a5-ee85-42a4-8c68-83f664cd9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e115c-e96b-47a1-81d5-c69809d399e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for UPDATE_METHOD in UPDATE_METHODS:\n",
    "    print('*'*80)\n",
    "    print(UPDATE_METHOD)\n",
    "    print('*'*80)\n",
    "\n",
    "    filename = f'./lm-eval-harness-res-{model_type}-{model_size}-{pii_type}/{UPDATE_METHOD}.pkl'\n",
    "    if not redo and os.path.exists(filename):\n",
    "        print(\"*\"*80)\n",
    "        print(\"ATTENZIONE GIA' CALCOLATO\")\n",
    "        print(\"Generazione al momento saltata\")\n",
    "        print(\"*\"*80)\n",
    "        print()\n",
    "        scores[UPDATE_METHOD] = load_pickle(filename)\n",
    "        continue\n",
    "\n",
    "    scores[UPDATE_METHOD] = {}  \n",
    "    if UPDATE_METHOD == 'pre_edit':\n",
    "        model_path = model_name\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    else:\n",
    "        if UPDATE_METHOD.startswith(\"memoedit\") or UPDATE_METHOD.startswith(\"MEMIT\"):\n",
    "            BATCH_SIZE = {'memoedit-200':8, 'MEMIT-200':8}[UPDATE_METHOD] # TODO da specificare a mano per ora\n",
    "            model_path = f\"../EasyEdit/edited_states_{model_type}-{model_size}/{UPDATE_METHOD.replace('-', '_')}_{BATCH_SIZE}_all_edited_states.pt\"\n",
    "        elif UPDATE_METHOD.startswith('dememorize'):\n",
    "            model_path = f\"../DeMemorization-main/{UPDATE_METHOD}_{model_type}-{model_size}\"\n",
    "        else:\n",
    "            model_path = f\"../EasyEdit/edited_states_{model_type}-{model_size}/{UPDATE_METHOD.replace('-', '_')}_all_edited_states.pt\"\n",
    "        \n",
    "        print(model_path)\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Edited states not computed, skipped!\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        if not UPDATE_METHOD.startswith('dememorize') and not UPDATE_METHOD.startswith('GRACE'):\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "            \n",
    "            #model = model.to(device)\n",
    "            \n",
    "            edited_layes = torch.load(model_path)#, map_location='auto')#torch.device(device))\n",
    "            edited_states = model.state_dict()\n",
    "            \n",
    "            for i in edited_layes.keys():\n",
    "                edited_states[f\"{i}.weight\"] = edited_layes[i]\n",
    "            \n",
    "            model.load_state_dict(edited_states)\n",
    "            del edited_states\n",
    "        elif UPDATE_METHOD.startswith('GRACE'):\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "            model = model.to(device)\n",
    "            model = GRACE.from_pretrained(\n",
    "                model=model,\n",
    "                device=device,\n",
    "                adapter_ckpt_path=model_path,\n",
    "                weights_only=False\n",
    "            )\n",
    "            model.activate_inference_state()\n",
    "            model=model.model\n",
    "        \n",
    "        else:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "            \n",
    "    #model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    model, tokenizer = accelerator.prepare(model, tokenizer)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    display(model)\n",
    "\n",
    "    # Load model wrapper\n",
    "    model = HFLM(pretrained=model, tokenizer=tokenizer, batch_size=8)\n",
    "\n",
    "    # Compute scores\n",
    "    for task in TASKS:\n",
    "        results = evaluator.simple_evaluate(\n",
    "            model=model,\n",
    "            tasks=[task],\n",
    "            num_fewshot=0,\n",
    "            limit=500,\n",
    "            bootstrap_iters=500 if model_size!='6B' else 50,\n",
    "            max_batch_size=32 if model_size!='6B' else 4\n",
    "        )\n",
    "\n",
    "        for t in results['results']: \n",
    "            scores[UPDATE_METHOD][t] = results['results'][t]\n",
    "    \n",
    "    model._model = model._model.to('cpu')\n",
    "    del model._model\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with open(filename, \"wb\") as pickle_handler:\n",
    "        pickle.dump(scores[UPDATE_METHOD], pickle_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13870bd-42db-4b18-bd20-0294121b15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_print_scores = {}\n",
    "for UPDATE_METHOD in scores:\n",
    "    for t in scores[UPDATE_METHOD]:\n",
    "        if t not in to_print_scores:\n",
    "            to_print_scores[t] = {}\n",
    "        to_print_scores[t][UPDATE_METHOD] = scores[UPDATE_METHOD][t]\n",
    "        to_print_scores[t][UPDATE_METHOD]['method'] = UPDATE_METHOD\n",
    "\n",
    "to_print_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6beab-644f-4d3f-b1ac-b1753d25a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = to_print_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a03bf-6023-4309-a674-bd46b628cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for t in scores:\n",
    "    df = pd.DataFrame([scores[t][UPDATE_METHOD] for UPDATE_METHOD in scores[t]])\n",
    "    display(df)\n",
    "    df.to_csv(f'lm-eval-harness-res-{model_type}-{model_size}-{pii_type}/{t}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff1f8b-fef1-430a-8dbe-d84c41a42d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92763005-3583-4e0f-8a2f-e4e497f9fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for t in scores:\n",
    "    df = pd.DataFrame([scores[t][UPDATE_METHOD] for UPDATE_METHOD in scores[t]])\n",
    "    df = df.rename(columns=lambda x: x if ',none' not in x else x.split(',none')[0])\n",
    "    \n",
    "    metric = df.columns[1]\n",
    "    df[f'{metric}_stderr'] = df[f'{metric}_stderr'].replace('N/A', 0)\n",
    "    \n",
    "    display(df[[metric, f'{metric}_stderr', 'method']])\n",
    "    dfs[t] = df[[metric, f'{metric}_stderr', 'method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a77ba8-ac85-47bd-911e-4371ebdb089e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26924c-b66b-4bbf-a471-abc2635c52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import to_hex, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def map_method_names(values):\n",
    "    new_names = []\n",
    "    mapping = {\n",
    "        'pre_edit': 'Pre Edit',\n",
    "    f'memoedit-{CONTEXT}': 'PME', \n",
    "    f'MEMIT-{CONTEXT}': 'MEMIT', \n",
    "    f'dememorize-{CONTEXT}': 'DeMem',\n",
    "    f'GRACE-{CONTEXT}': 'GRACE'\n",
    "\n",
    "    }\n",
    "    return [mapping[v] for v in values]\n",
    "    \n",
    "def rename_metric(x):\n",
    "    m = {\n",
    "        'acc': 'Accuracy↑',\n",
    "        'perplexity': 'Perplexity↓',\n",
    "        'word_perplexity': 'Word Perplexity↓'\n",
    "    }\n",
    "    return m[x]\n",
    "\n",
    "dataframes = []\n",
    "tasks = []\n",
    "\n",
    "for k, df in dfs.items():\n",
    "    dataframes.append(df)\n",
    "    tasks.append(k)\n",
    "\n",
    "# Custom forest green gradient\n",
    "forest_green_gradient = LinearSegmentedColormap.from_list(\n",
    "    \"forest_green_gradient\", [\"#a8e6a3\", \"#1b5e20\"]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(dataframes), figsize=(len(dataframes)*3, 3), sharey=False)\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "    ax = axes[i]\n",
    "    methods = map_method_names(df['method'].values)\n",
    "    metrics = df[df.columns[0]]\n",
    "    stds = df[df.columns[1]]\n",
    "\n",
    "    # Generate colors based on the number of methods\n",
    "    num_methods = len(methods)\n",
    "    colors = [to_hex(forest_green_gradient(j / (num_methods - 1))) for j in range(num_methods)]\n",
    "\n",
    "    # Plot bars with gradient colors\n",
    "    ax.bar(methods, metrics, capsize=5, color=colors, alpha=0.9)\n",
    "\n",
    "    ax.set_title(f\"{tasks[i].replace('_', ' ').capitalize()}\", fontsize=16)\n",
    "\n",
    "    # Custom limits and y-ticks\n",
    "    y_min = (metrics - stds).min() if sum(stds)!=0 else (metrics - 0.1).min()\n",
    "    y_max = (metrics + 1.2*stds).max() if sum(stds)!=0 else (metrics + 0.1).max()\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=6))\n",
    "    ax.set_ylabel(rename_metric(df.columns[0]), fontsize=16)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'lm-eval-harness-res-{model_type}-{model_size}-{pii_type}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604e35b-46ca-41dc-8d7d-59e3de7ca7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a02dd5-458e-4f5d-a257-1f6b073c848f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a036b6-f896-4321-a3c7-cf46a63f1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610747b7-a238-460c-910a-f3e200fa450c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2220733-8cf9-4878-b29d-40026cbd55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f4f9b-0371-4039-ab15-3405d0fcc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ceda7c-af59-456d-87da-f5a39512e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
