{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec514a-d810-4bb0-9fd4-306d294bd163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:08:23.678499Z",
     "start_time": "2024-06-04T14:08:23.352076Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248adfe-c193-4c6a-a89e-4f0c8ebe97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DEVICE_NUM = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=f\"{DEVICE_NUM}\" # f\"\" #\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d09569-802e-4e45-bb5c-1fbc5e43b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_types = ['phone', 'url']\n",
    "pii_type = pii_types[1]\n",
    "pii_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046db62-e5e0-4dbf-897d-e0e19082b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer\n",
    "import random\n",
    "\n",
    "\n",
    "device = f\"cuda:{DEVICE_NUM}\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "model_type = 'gpt-j' #'gpt-neo' # \n",
    "models = ['6B'] #['1.3B', '2.7B'] #\n",
    "model_size = models[0]\n",
    "\n",
    "\n",
    "\n",
    "if model_type == 'gpt-j':\n",
    "    model_name = f\"EleutherAI/gpt-j-{model_size}\"\n",
    "elif model_type == 'gpt-neo':\n",
    "    model_name = f\"EleutherAI/gpt-neo-{model_size}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737f08e-347c-4165-9e8f-71f7af75b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_type}-{model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c746350-dec4-424c-9cbe-37a8a4a23b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from ast import literal_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e03ba-419c-444e-85fb-b273982a5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21683d0-2d37-4436-88d6-59b23a533764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def clean_text_tokens(text):\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s)]\n",
    "\n",
    "    def tokens_and_remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        tokens = tokenize_text(text)\n",
    "        pattern = re.compile('[{}]'.format(re.escape(characters)))\n",
    "        return list(filter(None, [pattern.sub('', t) for t in tokens]))\n",
    "\n",
    "    text = text.lower() # lowercase\n",
    "    tokens = tokens_and_remove_special_characters(text) # remove punctuation and symbols\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def text_tokens(text, tokenizer):\n",
    "    tokens =  tokenizer(text)['input_ids']\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8054d-cff6-4d9b-a762-ebd957870e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36c5be-dcc0-4d5f-ab62-946f646d8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(f'generations-{model_type}-{model_size}'):\n",
    "    os.mkdir(f'generations-{model_type}-{model_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fe0b9-9876-43e6-8062-0966926fbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fa8d8-bec8-4eb1-99bb-89d3012aa2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_algs = [\"greedy\"]\n",
    "\n",
    "CONTEXT = 200\n",
    "\n",
    "UPDATE_METHODS = [f'memoedit-{CONTEXT}', f'MEMIT-{CONTEXT}', f'GRACE-{CONTEXT}', f'dememorize-{CONTEXT}']\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ola13/small-the_pile\")\n",
    "dataset = dataset['train']\n",
    "dataset = dataset.to_pandas()\n",
    "dataset['name'] = [x['pile_set_name'] for x in dataset['meta']]\n",
    "\n",
    "books = dataset[dataset['name'] == 'Books3']\n",
    "wikipedia = dataset[dataset['name'] == 'Wikipedia (en)']\n",
    "cc = dataset[dataset['name'] == 'Pile-CC']\n",
    "\n",
    "TEST = {'books':books, 'wikipedia':wikipedia, 'cc':cc}\n",
    "\n",
    "\n",
    "models=['gpt-neo-1.3B', 'gpt-neo-2.7B', 'gpt-j-6B']\n",
    "\n",
    "decoding_alg= 'greedy' \n",
    "\n",
    "redo = False\n",
    "\n",
    "for UPDATE_METHOD in UPDATE_METHODS:\n",
    "        print(\"*\"*80)\n",
    "        generations_completed = True\n",
    "        for sub in TEST:\n",
    "            if os.path.exists(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}-{pii_type}.csv'):\n",
    "                print(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}-{pii_type}.csv already exists')\n",
    "            else:\n",
    "                generations_completed = False\n",
    "        \n",
    "        if not redo and generations_completed:\n",
    "            continue\n",
    "\n",
    "        if UPDATE_METHOD.startswith(\"memoedit\") or UPDATE_METHOD.startswith(\"MEMIT\"):\n",
    "            BATCH_SIZE = {'memoedit-200':8, 'MEMIT-200':8}[UPDATE_METHOD] # TODO da specificare a mano per ora\n",
    "            model_path = f\"../EasyEdit/edited_states_{model_type}-{model_size}/{UPDATE_METHOD.replace('-', '_')}_{BATCH_SIZE}_{pii_type}_all_edited_states.pt\"\n",
    "        elif UPDATE_METHOD.startswith('dememorize'):\n",
    "            model_path = f\"../DeMemorization-main/{UPDATE_METHOD}_{model_type}-{model_size}_{pii_type}\"\n",
    "        else:\n",
    "            model_path = f\"../EasyEdit/edited_states_{model_type}-{model_size}/{UPDATE_METHOD.replace('-', '_')}_{pii_type}_all_edited_states.pt\"\n",
    "        \n",
    "        print(model_path)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Edited states not computed, skipped!\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        if UPDATE_METHOD!='MEND' and not UPDATE_METHOD.startswith('dememorize'):\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "            \n",
    "            model = model.to(device)\n",
    "            \n",
    "            edited_layes = torch.load(model_path, map_location=torch.device(device))\n",
    "            edited_states = model.state_dict()\n",
    "            \n",
    "            for i in edited_layes.keys():\n",
    "                edited_states[f\"{i}.weight\"] = edited_layes[i]\n",
    "                \n",
    "            model.load_state_dict(edited_states)\n",
    "        #elif UPDATE_METHOD.startswith('dememorize'):\n",
    "        #    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_path)\n",
    "        #    model = model.pretrained_model\n",
    "        else:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "            \n",
    "        model = model.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        #del edited_layes\n",
    "        torch.cuda.empty_cache()\n",
    "        display(model)\n",
    "    \n",
    "        generator = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device_map=\"auto\",\n",
    "            max_new_tokens=50\n",
    "            \n",
    "        )\n",
    "    \n",
    "        example = \"I met a nice old woman down the street yesterday and\"\n",
    "        generated_text = generator(example, do_sample=False, \n",
    "                                   generation_kwargs={\"max_new_tokens\":100, \"random_state\":42})[0]['generated_text']\n",
    "        print(generated_text)\n",
    "    \n",
    "        # Authomatic evaluation\n",
    "        for sub in TEST:\n",
    "            sample, _ = train_test_split(TEST[sub], train_size=100, random_state=42, shuffle=True)\n",
    "            sample['text_tokens'] = sample['text'].apply(clean_text_tokens)\n",
    "            sample['sample_text'] = [' '.join(x[int((len(x)/100)*20): int((len(x)/100)*20)+100]) for x in sample['text_tokens']]\n",
    "            display(sample)\n",
    "        \n",
    "        \n",
    "            generated = []\n",
    "            for p in tqdm.tqdm(sample['sample_text']):\n",
    "                generated_text = generator(p, do_sample=False, \n",
    "                                       generation_kwargs={\"random_state\":42})[0]['generated_text']\n",
    "                generated.append(generated_text)\n",
    "            \n",
    "            \n",
    "            sample['generated'] = generated\n",
    "            \n",
    "            sample[['sample_text','generated']].to_csv(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}-{pii_type}.csv')\n",
    "\n",
    "        model = model.to('cpu')\n",
    "        generator.model = generator.model.to('cpu')\n",
    "        del generator.model\n",
    "        del model\n",
    "        del generator\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d9ff7-5526-454f-b764-f24a8ee4b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d933b-f7d3-4d10-a3f6-210223c44918",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_METHOD = 'pre_edit'\n",
    "generations_completed = True\n",
    "for sub in TEST:\n",
    "    if os.path.exists(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}.csv'):\n",
    "        print(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}.csv already exists')\n",
    "    else:\n",
    "        generations_completed = False\n",
    "\n",
    "if not generations_completed:\n",
    "    if model_type == 'gpt-j':\n",
    "        model_name = f\"EleutherAI/gpt-j-{model_size}\"\n",
    "    elif model_type == 'gpt-neo':\n",
    "        model_name = f\"EleutherAI/gpt-neo-{model_size}\"\n",
    "    \n",
    "    model_path = model_name\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    #del edited_layes\n",
    "    torch.cuda.empty_cache()\n",
    "    display(model)\n",
    "    \n",
    "    generator = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\",\n",
    "        max_new_tokens=50\n",
    "        \n",
    "    )\n",
    "    \n",
    "    example = \"I met a nice old woman down the street yesterday and\"\n",
    "    generated_text = generator(example, do_sample=False, \n",
    "                               generation_kwargs={\"max_new_tokens\":100, \"random_state\":42})[0]['generated_text']\n",
    "    print(generated_text)\n",
    "    \n",
    "    # Authomatic evaluation\n",
    "    for sub in TEST:\n",
    "        sample, _ = train_test_split(TEST[sub], train_size=100, random_state=42, shuffle=True)\n",
    "        sample['text_tokens'] = sample['text'].apply(clean_text_tokens)\n",
    "        sample['sample_text'] = [' '.join(x[int((len(x)/100)*20): int((len(x)/100)*20)+100]) for x in sample['text_tokens']]\n",
    "        display(sample)\n",
    "    \n",
    "    \n",
    "        generated = []\n",
    "        for p in tqdm.tqdm(sample['sample_text']):\n",
    "            generated_text = generator(p, do_sample=False, \n",
    "                                   generation_kwargs={\"random_state\":42})[0]['generated_text']\n",
    "            generated.append(generated_text)\n",
    "        \n",
    "        \n",
    "        sample['generated'] = generated\n",
    "        \n",
    "        sample[['sample_text','generated']].to_csv(f'generations-{model_type}-{model_size}/generated_{sub}_{UPDATE_METHOD}.csv')\n",
    "    \n",
    "    model = model.to('cpu')\n",
    "    del model\n",
    "    del generator\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dce7ce-da65-4096-91bb-47b80fe45f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbd540-f6ca-418f-a404-417912bf60ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee52d6d-9a81-4917-827e-4bc259694574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32fb59-1c95-4358-b2cb-2c59e69d45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "decoding_algs = [\"greedy\"]\n",
    "\n",
    "CONTEXT = 200\n",
    "\n",
    "UPDATE_METHODS = [f'memoedit-{CONTEXT}', f'MEMIT-{CONTEXT}', f'GRACE-{CONTEXT}', f'dememorize-{CONTEXT}']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "update_prompts = [\"pre_edit\"] + UPDATE_METHODS\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ola13/small-the_pile\")\n",
    "dataset = dataset['train']\n",
    "dataset = dataset.to_pandas()\n",
    "dataset['name'] = [x['pile_set_name'] for x in dataset['meta']]\n",
    "\n",
    "books = dataset[dataset['name'] == 'Books3']\n",
    "wikipedia = dataset[dataset['name'] == 'Wikipedia (en)']\n",
    "cc = dataset[dataset['name'] == 'Pile-CC']\n",
    "\n",
    "TEST = {'books':books, 'wikipedia':wikipedia, 'cc':cc}\n",
    "\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for sub in TEST:\n",
    "    df = pd.DataFrame([])\n",
    "    for update_prompt in update_prompts:\n",
    "        if update_prompt!= 'pre_edit': \n",
    "            filename = f'generations-{model_type}-{model_size}/generated_{sub}_{update_prompt}-{pii_type}.csv'\n",
    "        else:\n",
    "            filename = f'generations-{model_type}-{model_size}/generated_{sub}_{update_prompt}.csv'\n",
    "        print(f\"Loading {filename}\")\n",
    "        if not os.path.exists(filename):\n",
    "            print('Not computed yet!')\n",
    "            continue\n",
    "            \n",
    "        sample = pd.read_csv(filename)\n",
    "        df[update_prompt] = sample['generated']\n",
    "        \n",
    "    \n",
    "    dfs[sub] = df\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850be232-1fc9-462d-a294-518203a55cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import exact_match\n",
    "from nltk.translate.nist_score import sentence_nist\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor\n",
    "from rouge_metric import PyRouge\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "class Metric:\n",
    "    def __init__(self, outputs, captions, clear=True, count_unk=False):\n",
    "        self.outputs = outputs\n",
    "        self.captions = captions\n",
    "        self.count_unk = count_unk\n",
    "        self.scores = {}\n",
    "        \n",
    "        self.scores = {'bleu':[], 'meteor':[]} #'rougeL':[], \n",
    "\n",
    "        if clear == True:\n",
    "            self._clear()\n",
    "\n",
    "    def _clear(self):\n",
    "        self.outputs = [[w for w in str(o).split()] for o in self.outputs]\n",
    "        self.captions = [[w for w in str(c).split()] for c in self.captions]\n",
    "\n",
    "    def call(self):\n",
    "        self._bleu_score()\n",
    "        #self._rogueL_score()\n",
    "        self._meteor_score()\n",
    "                \n",
    "        return self.scores\n",
    "\n",
    "    def _bleu_score(self):\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        \n",
    "        for i in tqdm.tqdm(range(len(self.outputs))):\n",
    "            # Calculate Bleu-4 score and\n",
    "            score = sentence_bleu([self.captions[i]], self.outputs[i], smoothing_function=smoothing)\n",
    "            self.scores['bleu'].append(score)\n",
    "\n",
    "\n",
    "    def _meteor_score(self):\n",
    "        for i in tqdm.tqdm(range(len(self.outputs))):\n",
    "            # Calculate meteor score and\n",
    "            score = meteor([self.captions[i]], self.outputs[i])\n",
    "            self.scores['meteor'].append(score)\n",
    "        \n",
    "\n",
    "    def _rogueL_score(self):\n",
    "        rouge = PyRouge(rouge_l=True)\n",
    "        for i in tqdm.tqdm(range(len(self.outputs))):\n",
    "            scores_rougeL = rouge.evaluate_tokenized([self.outputs[i]], [self.captions[i]])\n",
    "            \n",
    "            score = scores_rougeL['rouge-l']['f']\n",
    "            self.scores['rougeL'].append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dab80b-3d29-4f8a-8292-7fe48bc1ea6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449ec5d-a14a-4ab9-b48e-27f96d6391dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a274ee5-128a-4556-b90c-72713dff10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {sub:{} for sub in TEST}\n",
    "m1 = 'pre_edit'\n",
    "\n",
    "for sub in TEST:\n",
    "    for m2 in update_prompts:\n",
    "        if m2 != m1 and m1 in dfs[sub] and m2 in dfs[sub]:\n",
    "            metrics = Metric(outputs=dfs[sub][m2], captions=dfs[sub][m1])\n",
    "            scores[sub][(m1,m2)] = metrics.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ef33f-ccf7-4d9f-bb7a-4c7beb0e3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e60f69-c5ce-43ff-a59a-a4562744df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_scores = {sub:{} for sub in TEST}\n",
    "m1 = 'pre_edit'\n",
    "\n",
    "for sub in TEST:\n",
    "    for m2 in update_prompts:\n",
    "        if m2 != m1 and m1 in dfs[sub] and m2 in dfs[sub]:\n",
    "            stat_scores[sub][(m1,m2)] = {}\n",
    "            for score in scores[sub][(m1,m2)]:\n",
    "                \n",
    "                stat_scores[sub][(m1, m2)][score] = {\n",
    "                    'min': min(scores[sub][(m1, m2)][score]),\n",
    "                    'max': max(scores[sub][(m1, m2)][score]),\n",
    "                    'mean': stat.mean(scores[sub][(m1, m2)][score]),\n",
    "                    'median': stat.median(scores[sub][(m1, m2)][score]),\n",
    "                    'std': stat.stdev(scores[sub][(m1, m2)][score])\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42917009-aafd-4b3d-a3e2-3992c1451efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# T-test ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a015ed-3b4a-41b8-924d-c148012e3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bb9ce-399b-4cb8-af6a-d7226f9a88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = {sub:{} for sub in TEST}\n",
    "outs = []\n",
    "for sub in TEST:\n",
    "    for metric in ['bleu', 'meteor']: #'rougeL', \n",
    "        print(sub, metric)\n",
    "        df_results[sub][metric] = pd.DataFrame([stat_scores[sub][c][metric] for c in stat_scores[sub].keys()], \n",
    "                                               index=stat_scores[sub].keys())\n",
    "        display(df_results[sub][metric])\n",
    "\n",
    "        out = df_results[sub][metric][['mean', 'std']]\n",
    "        out['mean'] = out['mean'].apply(lambda x: round(x,3)).apply(str) + ' ('  + out['std'].apply(lambda x: round(x,3)).apply(str) + ')' \n",
    "        out = out[['mean']].rename(columns=lambda x: f'{sub}: {metric} {x}')\n",
    "        display(out)\n",
    "        \n",
    "        outs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291eb6be-a993-4417-a508-f5b426798870",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.concat(outs, axis=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacf3d5-89d3-4b20-bb96-cd878daa6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(f\"postedit_LM_{model_type}-{model_size}_{pii_type}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8da7fd-5cdb-45a9-b526-f05eed7bf504",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_type}-{model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd7aa9-87db-4511-a477-79b2482ff7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426353c1-c772-46c4-b8bc-8e601f2aa2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ecf37-c759-4879-a227-dba137fda77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
